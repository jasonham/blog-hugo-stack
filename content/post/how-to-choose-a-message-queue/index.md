---
title: 消息队列怎么选择
description: Kafka/RabbitMQ选型对比、消息可靠性保证（ACK、重试、死信队列）
date: 2024-05-17T00:22:19+08:00
lastmod: 2024-05-17T00:22:19+08:00
slug: how-to-choose-a-message-queue

tags:
  - kafaka
  - rabbitmq
categories:
  - 系统架构
---

## Kafka 与 RabbitMQ 选型对比

虽然两者都是“消息队列”，但**设计哲学、适用场景、性能特征、可靠性机制完全不同**。选型错误会导致架构瓶颈或运维灾难。

---

### 对比维度一览表

| 维度           | Kafka                                    | RabbitMQ                                        |
| -------------- | ---------------------------------------- | ----------------------------------------------- |
| **设计目标**   | 高吞吐、持久化日志、流式处理             | 低延迟、灵活路由、复杂消息模型                  |
| **消息模型**   | 发布-订阅（基于 Topic + Partition）      | 支持多种：点对点、发布订阅、RPC、Headers 路由等 |
| **吞吐量**     | 极高（百万级/秒），适合大数据场景        | 中等（万级/秒），适合业务系统                   |
| **延迟**       | 毫秒~秒级（批量写入+刷盘）               | 微秒~毫秒级（内存队列+ACK）                     |
| **消息顺序**   | 分区内严格有序                           | 队列内有序（单消费者），多消费者无序            |
| **持久化**     | 磁盘持久化（顺序写，性能高）             | 内存+可选磁盘（镜像队列）                       |
| **扩展性**     | 水平扩展极强（加 Partition + Broker）    | 扩展性弱（集群模式复杂，性能提升有限）          |
| **消费模式**   | Pull 模式（消费者主动拉取）              | Push 模式（Broker 推送给消费者）                |
| **适用场景**   | 日志收集、流处理、大数据管道、事件溯源   | 订单通知、任务分发、RPC、业务解耦               |
| **运维复杂度** | 较高（需管理 ZK、副本、ISR、监控）       | 较低（开箱即用，管理界面友好）                  |
| **社区生态**   | 大数据生态核心组件（Flink/Spark 集成好） | 传统企业应用广泛，插件丰富                      |

---

### 如何选型？

#### Kafka ：

- 需要**高吞吐量**（如用户行为日志、点击流、IoT 数据）
- 需要**持久化存储+重放能力**（如做离线分析、CDC）
- 需要对接**流处理引擎**（Flink/Spark Streaming）
- 消息允许**秒级延迟**
- 有专职运维或云平台支持

#### RabbitMQ ：

- 需要**低延迟、实时响应**（如支付回调、短信通知）
- 需要**复杂路由规则**（如按 Header、Topic、Fanout 分发）
- 消息量不大（< 10 万/秒），但对**消息模型灵活性**要求高
- 希望**快速部署、图形化管理**
- 业务系统解耦、异步任务、RPC 场景

> 举个例子：
>
> - 用户下单 → 发送“订单创建”事件 → 更新库存、发券、通知用户 → 选 **RabbitMQ**（低延迟、可靠、灵活路由）
> - 用户点击行为 → 实时收集 → 实时推荐 + 离线分析 → 选 **Kafka**（高吞吐、可重放、对接 Flink）

---

## 消息可靠性保证机制

无论选哪个 MQ，**消息不丢、不重、有序（如需）** 是核心诉求。我们从三个层面保障：

---

### 生产者端可靠性（消息不丢）

#### Kafka：

- `acks` 参数控制：
  - `acks=0`：不等待确认 → 吞吐高，可能丢消息
  - `acks=1`：Leader 确认 → 平衡性能与可靠性
  - `acks=all`（或 -1）：所有 ISR 副本确认 → 最安全，性能最低
- 重试机制：`retries` + `retry.backoff.ms`
- 幂等生产者（`enable.idempotence=true`）：避免重试导致重复（需配合 `acks=all`）
- 事务支持（Kafka Transactions）：实现跨分区原子写入（用于 Exactly-Once 语义）

#### RabbitMQ：

- 发布确认模式（Publisher Confirms）：
  - 异步监听 `basic.ack` / `basic.nack`
  - 可配合事务（性能差，不推荐）或 Confirm 模式（推荐）
- 消息持久化：`delivery_mode=2` + 队列 durable=true
- 生产者重试 + 本地缓存未确认消息（防止网络抖动）

> 最佳实践：生产者本地记录“待确认消息”，收到 ACK 后清除，超时/NACK 则重发或告警。

---

### Broker 端可靠性（消息不丢）

#### Kafka：

- 副本机制（Replication）：每个 Partition 有多个副本（Leader + Follower）
- ISR（In-Sync Replicas）：只有同步副本才参与选举和写入确认
- `min.insync.replicas`：控制最少同步副本数（如设为 2，配合 `acks=all` 保证至少 2 副本写入）
- 日志刷盘策略（`flush.messages`, `flush.ms`）→ 但通常依赖 OS PageCache，性能优先

#### RabbitMQ：

- 镜像队列（Mirrored Queues）：队列内容在多个节点复制
- 持久化队列 + 持久化消息（写磁盘）
- 但注意：RabbitMQ 持久化性能较差，高吞吐场景慎用

> 注意：Kafka 默认不立即刷盘，靠副本机制保证可靠性；RabbitMQ 持久化会显著降低吞吐。

---

### 消费者端可靠性（消息不丢不重）

#### 通用机制：

##### ACK 机制（手动确认）

- 消费者处理完业务逻辑后，**手动发送 ACK**，Broker 才删除消息
- 若消费者崩溃/超时，消息重新入队（或进死信队列）

##### 重试机制

- 本地重试（try-catch + sleep + 重试 N 次）
- 重试队列（把失败消息发到另一个队列，延迟消费）
- 指数退避 + 最大重试次数

##### 死信队列（DLQ - Dead Letter Queue）

- 当消息多次重试失败、被拒绝、TTL 过期，自动转入 DLQ
- 用于人工排查、修复后重新投递
- Kafka：无原生 DLQ，需自建 Topic 或用 Kafka Streams 处理
- RabbitMQ：原生支持，通过参数 `x-dead-letter-exchange` 配置

##### 幂等消费（防重复）

- 因网络抖动、ACK 丢失、消费者重启，可能导致消息重复
- 解决方案：
  - 数据库唯一键约束（如订单号）
  - Redis 分布式锁/SETNX（带过期时间）
  - 业务层状态机（如“订单状态=已支付”，重复消息直接忽略）

> 消费者最佳实践：
>
> 1. 手动 ACK
> 2. 先处理业务，再 ACK（避免处理失败但已 ACK）
> 3. 业务逻辑幂等化
> 4. 失败消息进重试队列 → 最终进死信队列
> 5. 监控消费延迟、积压、失败率

---

## 总结：

| 项目         | Kafka                              | RabbitMQ                    |
| ------------ | ---------------------------------- | --------------------------- |
| 选型关键词   | 吞吐、日志、流处理、重放           | 低延迟、灵活路由、业务解耦  |
| 可靠性核心   | 副本 + ISR + acks=all + 幂等       | Confirm + 持久化 + 镜像队列 |
| 消费确认     | 手动 commit offset                 | 手动 basic.ack              |
| 死信机制     | 自建 Topic / Streams 处理          | 原生 DLX + DLQ              |
| Exactly-Once | 事务 + 幂等（Flink/Kafka Streams） | 业务层幂等 + 唯一 ID        |
